{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##import the libs"
      ],
      "metadata": {
        "id": "Fq1hQ8QRBECP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "\n",
        "import cv2\n",
        "from glob import glob\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model, load_model, save_model\n",
        "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose, MaxPooling2D, concatenate, AveragePooling2D, Dense, Flatten, MaxPool2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "GOPxSkrABKC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "f300RN4Wv_zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/"
      ],
      "metadata": {
        "id": "5f6e2fWxwAKM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip dataset.zip"
      ],
      "metadata": {
        "id": "WcQtlrsZwFmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir_img = 'dataset/3_channel/' \n",
        "train_dir_mask = 'dataset/mask/'"
      ],
      "metadata": {
        "id": "nHogRTf4wF_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_h = 256\n",
        "img_w = 256\n",
        "batch_size = 4\n"
      ],
      "metadata": {
        "id": "231JHu18xNPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs = []\n",
        "for path, subdirs, files in os.walk(train_dir_img):\n",
        "    for name in files:\n",
        "        train_imgs.append(os.path.join(path, name))"
      ],
      "metadata": {
        "id": "eEREkc6wxNfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs"
      ],
      "metadata": {
        "id": "M50OwhK9xNt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_imgs)"
      ],
      "metadata": {
        "id": "zAW2Cnq1xN6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_masks = []\n",
        "for path, subdirs, files in os.walk(train_dir_mask):\n",
        "    for name in files:\n",
        "        train_masks.append(os.path.join(path, name))"
      ],
      "metadata": {
        "id": "fquMG00GxOGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_masks"
      ],
      "metadata": {
        "id": "TNdydvlKxOS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_masks)"
      ],
      "metadata": {
        "id": "OyMU97VkxOfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs.sort()\n",
        "train_masks.sort()"
      ],
      "metadata": {
        "id": "TfX4NQMPxcJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs"
      ],
      "metadata": {
        "id": "yys_jtMlxeWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_masks"
      ],
      "metadata": {
        "id": "kyqwwQpmxluz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define X and Y as number of images along with shape of one image\n",
        "X_t = np.zeros((len(train_imgs),img_h,img_w,3), dtype=np.float32)\n",
        "y_t = np.zeros((len(train_imgs),img_h,img_w,3), dtype=np.float32)"
      ],
      "metadata": {
        "id": "LxXtxgckxp37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_t.shape)\n",
        "\n",
        "print(y_t.shape)"
      ],
      "metadata": {
        "id": "JNM5QANcxuPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, i_d in enumerate(train_imgs):\n",
        "    \n",
        "    img = cv2.imread(i_d)\n",
        "    img = cv2.resize(img, (img_h, img_w))\n",
        "    X_t[i] = img"
      ],
      "metadata": {
        "id": "UYhwezMsxxVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t"
      ],
      "metadata": {
        "id": "AJddQC-dx0Ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t.shape"
      ],
      "metadata": {
        "id": "G5yLiiDcx2pW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, i_d in enumerate(train_masks):\n",
        "    img = cv2.imread(i_d)\n",
        "    #print(img)\n",
        "    img = cv2.resize(img, (img_h, img_w))\n",
        "    y_t[i] = img"
      ],
      "metadata": {
        "id": "Rqd3acIEx43e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_t"
      ],
      "metadata": {
        "id": "Es_oRq8Yx7ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_t.shape"
      ],
      "metadata": {
        "id": "RdnQV1fix9ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_t[0].shape"
      ],
      "metadata": {
        "id": "E1gf-yilyASY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_t[0]"
      ],
      "metadata": {
        "id": "XT-cUaqn9p_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# train_gen = ImageDataGenerator(rescale = 1./255)\n",
        "#   # rotation_range=30,\n",
        "#   #                             height_shift_range=0.3,\n",
        "#   #                             zoom_range=0.3,\n",
        "#   #                             horizontal_flip=True,\n",
        "#   #                             width_shift_range=0.3,\n",
        "#   #                             fill_mode='reflect\n",
        "# val_gen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "FcCO5VD0yCXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "xt, xv, yt, yv = train_test_split(X_t, y_t, test_size=0.2)"
      ],
      "metadata": {
        "id": "UNhjnQbZyEs_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.io import imshow\n",
        "y = yv[22][:,:,0]\n",
        "imshow(y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NSBjNQ-byHja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = xv[22][:,:,0]\n",
        "imshow(y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0K6bcRoryMwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1TwtbXFdyXLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# seed=42\n",
        "# def combineGenerator(gen1, gen2):\n",
        "#     while True:\n",
        "#         yield(gen1.next(), gen2.next())\n",
        "\n",
        "# train_generator_image = train_gen.flow(xt,batch_size=16, seed=seed, shuffle=True)\n",
        "# train_generator_mask = train_gen.flow(yt, batch_size=16, seed=seed, shuffle=True)\n",
        "# train_generator = combineGenerator(train_generator_image, train_generator_mask)\n",
        "# validation_generator_image = val_gen.flow(xv, batch_size=16, seed=seed, shuffle=True)\n",
        "# validation_generator_mask = val_gen.flow(yv, batch_size=16, seed=seed, shuffle=True)\n",
        "# validation_generator = combineGenerator(validation_generator_image, validation_generator_mask)"
      ],
      "metadata": {
        "id": "hVjqxmOsyb5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a, b = next(validation_generator)\n",
        "# print(a.shape, b.shape)"
      ],
      "metadata": {
        "id": "PNEqSKdgyfbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img1, mask1 = next(train_generator)\n",
        "\n",
        "# fig=plt.figure(figsize=(12,12))\n",
        "# columns = 2\n",
        "# rows = 4\n",
        "# counter = 0\n",
        "# c = 0\n",
        "# for i in range(1, columns*rows +1):\n",
        "#     #img = np.random.randint(10, size=(h,w))\n",
        "#     fig.add_subplot(rows, columns, i)\n",
        "#     if counter%2 == 0:\n",
        "#         plt.imshow(img1[c])\n",
        "#     else:\n",
        "#         plt.imshow(mask1[c][:,:,0])\n",
        "#         c = c + 1\n",
        "#     counter = counter + 1\n",
        "    \n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "wfy9kJY8yiGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bn_act(x, act=True):\n",
        "    x = keras.layers.BatchNormalization()(x)\n",
        "    if act==True:\n",
        "        x = keras.layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def conv_block(x, filters, kernel_size=(3,3), padding='same', strides=1):\n",
        "    conv = bn_act(x)\n",
        "    conv = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
        "    return conv\n",
        "\n",
        "def stem(x, filters, kernel_size=(3,3), padding='same', strides=1):\n",
        "    conv = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
        "    \n",
        "    shortcut = keras.layers.Conv2D(filters, kernel_size=(1,1), padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "    \n",
        "    output = keras.layers.Add()([conv, shortcut])\n",
        "    return output\n",
        "\n",
        "def residual_block(x, filters, kernel_size=(3,3), padding='same', strides=1):\n",
        "    conv = conv_block(x, filters, kernel_size=kernel_size, padding=padding, strides=strides)\n",
        "    conv = conv_block(conv, filters, kernel_size=kernel_size, padding=padding, strides=1)\n",
        "    \n",
        "    shortcut = keras.layers.Conv2D(filters, kernel_size=(1,1), padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "    \n",
        "    output = keras.layers.Add()([shortcut, conv])\n",
        "    return output\n",
        "\n",
        "def up_sampling_concat_block(x, x_skip):\n",
        "    up_sample = keras.layers.UpSampling2D((2,2))(x)\n",
        "    concat = keras.layers.Concatenate()([up_sample, x_skip])\n",
        "    return concat\n",
        "    "
      ],
      "metadata": {
        "id": "SG0-WTsyylVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ResUnet():\n",
        "    f = [16,32,64,128,256]\n",
        "    img_=256\n",
        "    inputs = keras.layers.Input((img_, img_,3))\n",
        "    \n",
        "    #encoding\n",
        "    e0 = inputs\n",
        "    e1 = stem(e0, f[0])\n",
        "    e2 = residual_block(e1, f[1], strides=2)\n",
        "    e3 = residual_block(e2, f[2], strides=2)\n",
        "    e4 = residual_block(e3, f[3], strides=2)\n",
        "    e5 = residual_block(e4, f[4], strides=2)\n",
        "    \n",
        "    #bridge\n",
        "    b0 = conv_block(e5, f[4], strides=1)\n",
        "    b1 = conv_block(b0, f[4], strides=1)\n",
        "    \n",
        "    #decoder\n",
        "    u0 = up_sampling_concat_block(b1, e4)\n",
        "    d0 = residual_block(u0, f[4])\n",
        "    \n",
        "    u1 = up_sampling_concat_block(d0, e3)\n",
        "    d1 = residual_block(u1, f[3])\n",
        "    \n",
        "    u2 = up_sampling_concat_block(d1, e2)\n",
        "    d2 = residual_block(u2, f[2])\n",
        "    \n",
        "    u3 = up_sampling_concat_block(d2, e1)\n",
        "    d3 = residual_block(u3, f[1])\n",
        "    \n",
        "    output = keras.layers.Conv2D(3, (1,1), padding='same', activation='sigmoid')(d3)\n",
        "    model = keras.models.Model(inputs, output)\n",
        "    return model"
      ],
      "metadata": {
        "id": "zb77bW3vyz4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Flatten"
      ],
      "metadata": {
        "id": "qVQaie8sy2gA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smooth = 1.\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    flatten_layer = Flatten()\n",
        "    y_true_f = flatten_layer(y_true)\n",
        "    y_pred_f = flatten_layer(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "dBLhehDTy4nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "model = ResUnet()\n",
        "model.compile(optimizer=Adam(lr=0.0005), loss=dice_coef_loss, metrics=[dice_coef])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "IFLJsXuey-AB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import  ModelCheckpoint\n",
        "\n",
        "callbacks=[ModelCheckpoint(monitor='val_loss',\n",
        "                             filepath='dsb.h5',\n",
        "                             save_best_only=True)]\n",
        "\n",
        "history = model.fit(xt,yt, epochs = 20,\n",
        "                              validation_data = (xv,yv), callbacks=callbacks)"
      ],
      "metadata": {
        "id": "uXcvDg6QzAmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.history.keys()"
      ],
      "metadata": {
        "id": "opy1bsRGzF8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,15))\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(model.history.history['loss'], 'b-', label='train_loss')\n",
        "plt.plot(model.history.history['val_loss'], 'r-', label='val_loss')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Loss')\n",
        "\n",
        "# plt.subplot(3,1,2)\n",
        "# plt.plot(model.history.history['dice_coef'], 'b-', label='train_iou')\n",
        "# plt.plot(model.history.history['val_dice_coef'], 'r-', label='val_iou')\n",
        "# plt.legend(loc='best')\n",
        "# plt.title('IoU')\n",
        "\n",
        "plt.subplot(3,1,2)\n",
        "plt.plot(model.history.history['dice_coef'], 'b-', label='train_dice_coef')\n",
        "plt.plot(model.history.history['val_dice_coef'], 'r-', label='val_dice_coef')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Dice Coef')"
      ],
      "metadata": {
        "id": "CGEhnDGw1fcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(xv, yv)\n"
      ],
      "metadata": {
        "id": "IEKyheeD1fyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Results of Validation Dataset\n",
        "def VisualizeResults(index):\n",
        "    img = xv[index]\n",
        "    img = img[np.newaxis, ...]\n",
        "    pred_y = model.predict(img)\n",
        "    pred_mask = tf.argmax(pred_y[0], axis=-1)\n",
        "    pred_mask = pred_mask[..., tf.newaxis]\n",
        "    fig, arr = plt.subplots(1, 3, figsize=(15, 15))\n",
        "    arr[0].imshow(xv[index,:,:,0])\n",
        "    arr[0].set_title('Processed Image')\n",
        "    arr[1].imshow(yv[index,:,:,0])\n",
        "    arr[1].set_title('Actual Masked Image ')\n",
        "    arr[2].imshow(pred_mask[:,:,0])\n",
        "    arr[2].set_title('Predicted Masked Image ')"
      ],
      "metadata": {
        "id": "HgDr2DWF14hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index = 35\n",
        "VisualizeResults(index)"
      ],
      "metadata": {
        "id": "BohWMyDg2II_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('dsb.h5', custom_objects={'dice_coef_loss': dice_coef_loss,'dice_coef':dice_coef})\n"
      ],
      "metadata": {
        "id": "evJ5NW7x7UFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_mask = model.predict(xv, verbose=1)"
      ],
      "metadata": {
        "id": "X5W3kR9G2MSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_mask[0].shape"
      ],
      "metadata": {
        "id": "9W3hq2yoABeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#preds_test_t = (test_mask > 0.5)"
      ],
      "metadata": {
        "id": "c3QM7l2YD3kP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = random.randint(0, len(xv)-1)\n",
        "\n",
        "fig = plt.figure(figsize = (10,10))\n",
        "fig.subplots_adjust(hspace=0.2, wspace=0.2)\n",
        "ax = fig.add_subplot(1, 3, 1)\n",
        "ax.imshow(xv[r][:,:,0])\n",
        "ax = fig.add_subplot(1, 3, 2)\n",
        "ax.imshow(yv[r][:,:,0])\n",
        "\n",
        "ax = fig.add_subplot(1,3,3)\n",
        "ax.imshow(test_mask[r][:,:,0])\n"
      ],
      "metadata": {
        "id": "VtPrVuIS7GCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jc9aV2mN_c6l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}